{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 1024)\n",
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "import scipy.io as io\n",
    "import numpy as np\n",
    "from fire import Fire\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "raw_table = pd.read_csv('task2/TrainSamples-300.csv', header=None)\n",
    "train_data = np.array(raw_table).astype(np.float32)\n",
    "print(train_data.shape)\n",
    "# print(train_data[:10])\n",
    "\n",
    "raw_table = pd.read_csv('task2/TrainLabels-300.csv', header=None)\n",
    "train_label = np.array(raw_table).reshape(-1).astype(np.long)\n",
    "print(train_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: 0\t I: 289\t  acc:0.783\t\n",
      "E: 1\t I: 289\t  acc:0.821\t\n",
      "E: 2\t I: 289\t  acc:0.839\t\n",
      "E: 3\t I: 289\t  acc:0.842\t\n",
      "E: 4\t I: 289\t  acc:0.844\t\n",
      "E: 5\t I: 289\t  acc:0.849\t\n",
      "E: 6\t I: 289\t  acc:0.856\t\n",
      "E: 7\t I: 289\t  acc:0.855\t\n",
      "E: 8\t I: 289\t  acc:0.858\t\n",
      "E: 9\t I: 289\t  acc:0.853\t\n",
      "E: 10\t I: 289\t  acc:0.853\t\n",
      "E: 11\t I: 289\t  acc:0.856\t\n",
      "E: 12\t I: 289\t  acc:0.851\t\n",
      "E: 13\t I: 289\t  acc:0.852\t\n",
      "E: 14\t I: 289\t  acc:0.858\t\n",
      "E: 15\t I: 289\t  acc:0.86\t\n",
      "E: 16\t I: 289\t  acc:0.859\t\n",
      "E: 17\t I: 289\t  acc:0.854\t\n",
      "E: 18\t I: 289\t  acc:0.854\t\n",
      "E: 19\t I: 289\t  acc:0.857\t\n",
      "E: 20\t I: 289\t  acc:0.857\t\n",
      "E: 21\t I: 289\t  acc:0.854\t\n",
      "E: 22\t I: 289\t  acc:0.855\t\n",
      "E: 23\t I: 289\t  acc:0.854\t\n",
      "E: 24\t I: 289\t  acc:0.86\t\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "split_sep = 29000\n",
    "test_data = train_data[split_sep:]\n",
    "test_label = train_label[split_sep:]\n",
    "\n",
    "train_data = train_data[:split_sep]\n",
    "train_label = train_label[:split_sep]\n",
    "\n",
    "\n",
    "\n",
    "class my_clsifer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_c,\n",
    "        output_c,\n",
    "    ):\n",
    "        super(my_clsifer, self).__init__()\n",
    "        self.func = nn.Sequential(\n",
    "            nn.Linear(input_c, input_c * 2),\n",
    "            nn.BatchNorm1d(input_c * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_c * 2, input_c * 2),\n",
    "            nn.BatchNorm1d(input_c * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_c * 2, output_c * 10),\n",
    "            nn.BatchNorm1d(output_c * 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_c * 10, output_c),\n",
    "        )\n",
    "\n",
    "        # self.a = nn.Linear(input_c, input_c * 2)\n",
    "        # self.b = nn.BatchNorm1d(input_c * 2)\n",
    "        # # nn.ReLU(),\n",
    "        # self.c = nn.Linear(input_c * 2, input_c * 2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.func(input)\n",
    "        # x = self.a(input)\n",
    "        # x = self.b(x)\n",
    "        # x = self.c(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class my_dataset(data.Dataset):\n",
    "    def __init__(self, datasource, labels, norm_bound=None):\n",
    "        self.data_ = datasource\n",
    "        self.labels = labels\n",
    "\n",
    "        if norm_bound:\n",
    "            self.data_ /= (norm_bound * 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_[index], self.labels[index]\n",
    "\n",
    "\n",
    "my_model = my_clsifer(1024, 100).cuda()\n",
    "\n",
    "dataloader = data.DataLoader(my_dataset(train_data, train_label),\n",
    "                             batch_size=100,\n",
    "                             shuffle=True,\n",
    "                             pin_memory=True,\n",
    "                             num_workers=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=5e-5)\n",
    "\n",
    "test_loader = data.DataLoader(my_dataset(test_data, test_label),\n",
    "                              batch_size=1,\n",
    "                              shuffle=False,\n",
    "                              pin_memory=True)\n",
    "\n",
    "\n",
    "def test_(model, test_loader):\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for iteration, batch in enumerate(test_loader):\n",
    "            count += 1\n",
    "            data_, label_ = batch\n",
    "            data_, label_ = data_.cuda(), label_.cuda()\n",
    "            output = model(data_.to(torch.float32))\n",
    "\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            if int(output.item()) == label_.item():\n",
    "                acc += 1\n",
    "\n",
    "    return acc / count\n",
    "\n",
    "\n",
    "epochs = 25\n",
    "for i in range(epochs):\n",
    "    for iteration, batch in enumerate(dataloader):\n",
    "        # print(batch)\n",
    "        # break\n",
    "\n",
    "        my_model.train()\n",
    "        data_, label_ = batch\n",
    "        data_, label_ = data_.cuda(), label_.cuda()\n",
    "        output = my_model(data_.to(torch.float32))\n",
    "\n",
    "        loss_ = criterion(output, label_.long())\n",
    "        loss_.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # if iteration % 100 == 0:\n",
    "\n",
    "        #     acc = test_(my_model, test_loader)\n",
    "        #     # acc = 0\n",
    "        #     print('E: {}\\t I: {}\\t Loss:{:.6f}\\t acc:{}\\t'.format(i, iteration, loss_, acc))\n",
    "\n",
    "    acc = test_(my_model, test_loader)\n",
    "    # acc = 0\n",
    "    print('E: {}\\t I: {}\\t  acc:{}\\t'.format(i, iteration, acc))\n",
    "\n",
    "torch.save(my_model, 'task2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1024)\n"
     ]
    }
   ],
   "source": [
    "raw_table = pd.read_csv('task2/TestSamples-300.csv', header=None)\n",
    "test_data_new = np.array(raw_table).astype(np.float32)\n",
    "print(test_data_new.shape)\n",
    "\n",
    "\n",
    "\n",
    "class my_dataset(data.Dataset):\n",
    "    def __init__(self, datasource, labels, norm_bound=None):\n",
    "        self.data_ = datasource\n",
    "        self.labels = labels\n",
    "\n",
    "        if norm_bound:\n",
    "            self.data_ /= (norm_bound * 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.labels is not None:\n",
    "            return self.data_[index], self.labels[index]\n",
    "        else:\n",
    "            return self.data_[index]\n",
    "\n",
    "test_loader = data.DataLoader(my_dataset(test_data_new, None),\n",
    "                              batch_size=1,\n",
    "                              shuffle=False,\n",
    "                              pin_memory=True)\n",
    "\n",
    "my_model.eval()\n",
    "\n",
    "result = []\n",
    "with torch.no_grad():\n",
    "    for iteration, batch in enumerate(test_loader):\n",
    "        data_ = batch\n",
    "        data_ = data_.cuda()\n",
    "        output = my_model(data_.to(torch.float32))\n",
    "\n",
    "        output = torch.argmax(output, dim=1)\n",
    "        result.append(output.item())\n",
    "\n",
    "result = np.array(result, dtype=np.int).reshape(-1, 1)\n",
    "data_frame = pd.DataFrame(result)\n",
    "\n",
    "data_frame.to_csv('task2/TestLabels__21S003010.csv', header=0, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1c2329b2607c678340558ea3c608c71bb4d3ba9a6eaf9628a2ac26414c7b0df"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('deeplab-pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
